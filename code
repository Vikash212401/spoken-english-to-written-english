import pandas as pd
import numpy as np
np.random.seed(42)

df = pd.read_csv(filepath_or_buffer='../input/spoken_english.txt', dtype='str')
df.head()

df = df.sample(frac=1, random_state=42)
roman_values = df.loc[:, 'spoken_english'].astype(np.str)
ha_values = df.loc[:, 'HA'].astype(np.str)

import keras
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical

written_english_tokenizer = Tokenizer(char_level=True)
written_english_tokenizer.fit_on_texts(written_english)

ha_tokenizer = Tokenizer(char_level=True)
ha_tokenizer.fit_on_texts(ha_values)

spoken_english_index_to_char = {v:k for k,v in roman_tokenizer.word_index.items()}
spoken_english_index_to_char

ha_index_to_char = {v:k for k,v in ha_tokenizer.word_index.items()}
ha_index_to_char

x_roman_1 = spoken_english.texts_to_matrix(roman_values)
x_roman_2 = spoken_english.texts_to_matrix(roman_values, mode='count')
# Spatial Inputs
x_roman_3 = pad_sequences(roman_tokenizer.texts_to_sequences(roman_values), padding='pre')

num_ex = x_roman_3.shape[0]
spoken_english_seq_len = x_spoken_english_3.shape[1]
spoken_english_vocab_size = len(spoken_english_index_to_char) + 1

arr = [to_categorical(x_spoken_english_3[i], num_classes=spoken_english_vocab_size) for i in range(num_ex)]
arr = [item.reshape(spoken_english_seq_len * spoken_english_vocab_size,) for item in arr]
temp = np.vstack(arr)
x_spoken_english_3 = temp.reshape((num_ex,spoken_english_seq_len,spoken_english_vocab_size))

x_spoken_english_3.shape

y_ha = ha_tokenizer.texts_to_sequences(ha_values)
y_ha = pad_sequences(y_ha, padding='post')
ha_seq_len = y_ha.shape[1]
ha_vocab_size = len(ha_index_to_char) + 1
arr = [to_categorical(y_ha[i], num_classes=ha_vocab_size) for i in range(num_ex)]
arr = [item.reshape(ha_seq_len * ha_vocab_size,) for item in arr]
temp = np.vstack(arr)
y_ha = temp.reshape((num_ex,ha_seq_len,ha_vocab_size))

from keras.models import Sequential, Model
from keras.layers import Dense, Activation, SimpleRNN, LSTM, RepeatVector, Flatten,  Input, Reshape
NON_SPATIAL_INPUT_DIM = x_roman.shape[1]

input1_nonspatial = Input(shape=(NON_SPATIAL_INPUT_DIM,))

input2_spatial = Input(shape=(roman_seq_len, spoken_english_vocab_size))
intm = LSTM(20)(input2_spatial)
intm = RepeatVector(ha_seq_len)(intm)
intm = LSTM(20, return_sequences=True)(intm)
intm = LSTM(20, return_sequences=True)(intm)
rnn_output = Flatten()(intm)

concatenated = keras.layers.concatenate([input1_nonspatial, rnn_output])

intm = Dense(ha_vocab_size*ha_seq_len*2)(concatenated)
intm = Activation('relu')(intm)

intm = Dense(ha_vocab_size*ha_seq_len)(intm)
intm = Reshape(target_shape=(ha_seq_len, ha_vocab_size))(intm)
output = Activation('softmax')(intm)

model = Model(inputs=[input1_nonspatial, input2_spatial], outputs=output)
model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

model.summary()
model.fit(x=[x_spoken_english, x_spoken_english_3], y=y_ha, epochs=1000, validation_split=0.3, batch_size=10)

y_pred = model.predict([x_spoken_english,x_spoken_english_3])
y_pred.shape
y_pred=y_pred.reshape((num_ex,ha_seq_len * ha_vocab_size))

NUM_PER_CHAR = ha_vocab_size
results = []
for i in (range(y_pred.shape[0])):
    char1_one_hot = y_pred[i,0:11]
    char1_encoded = np.argmax(char1_one_hot)
    char1 = ''
    if char1_encoded != 0:
        char1 = ha_index_to_char[char1_encoded]    
    
    char2_one_hot = y_pred[i,11:]
    char2_encoded = np.argmax(char2_one_hot)
    char2 = ''
    if char2_encoded != 0:
        char2 = ha_index_to_char[char2_encoded]
    results.append(char1 + char2)
    
for x,y in zip(list(spoken_english), results):
    print(x,'\t',y
